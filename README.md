# Adapting-ImageNet-Classification-Techniques-for-CIFAR100-with-Modified-AlexNet
Adapting ImageNet Classification Techniques for CIFAR100 with Modified AlexNet Architecture and ADAMW Optimizer

The  pursuit  of  improved  performance  in  deep  convolutional  neural  networks(CNNs) for image classification remains a key challenge in computer vision.  This study  investigates  the  performance  of  Stochastic  Gradient  Descent  (SGD)  andADAMW optimizers on a replicated model of Alex Krizhevskyâ€™s architecture, originally  developed  for  ImageNet  classification,  using  the  CIFAR100  dataset.   Our findings reveal a fascinating trade-off between training loss and accuracy, highlighting the importance of tailoring optimizer selection to specific model objectives.
